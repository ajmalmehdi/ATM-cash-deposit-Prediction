{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T13:08:11.138407Z","iopub.status.busy":"2025-05-23T13:08:11.137979Z","iopub.status.idle":"2025-05-23T13:08:36.961114Z","shell.execute_reply":"2025-05-23T13:08:36.959423Z","shell.execute_reply.started":"2025-05-23T13:08:11.138384Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_97/2304650500.py:1: DtypeWarning: Columns (2,8) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df=pd.read_csv('/kaggle/input/atm-data/merged_atm_data.csv')\n"]}],"source":["import pandas as pd \n","df=pd.read_csv('../data/cleaned/merged_atm_data.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T13:08:36.964152Z","iopub.status.busy":"2025-05-23T13:08:36.963809Z","iopub.status.idle":"2025-05-23T13:08:36.994807Z","shell.execute_reply":"2025-05-23T13:08:36.993533Z","shell.execute_reply.started":"2025-05-23T13:08:36.964125Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>atm_id</th>\n","      <th>date</th>\n","      <th>amount</th>\n","      <th>BRANCH_NAME</th>\n","      <th>CITY_CODE</th>\n","      <th>city</th>\n","      <th>city.1</th>\n","      <th>region</th>\n","      <th>day_off_discription</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2009-01-02</td>\n","      <td>17200</td>\n","      <td>zerktouni</td>\n","      <td>780</td>\n","      <td>casablanca</td>\n","      <td>Casablanca</td>\n","      <td>casablanca-settat</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>2009-01-02</td>\n","      <td>163300</td>\n","      <td>zerktouni</td>\n","      <td>780</td>\n","      <td>casablanca</td>\n","      <td>Casablanca</td>\n","      <td>casablanca-settat</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>2009-01-02</td>\n","      <td>306900</td>\n","      <td>centre d'affaire trabless</td>\n","      <td>810</td>\n","      <td>rabat</td>\n","      <td>Rabat</td>\n","      <td>rabat-sale-kenitra</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>2009-01-02</td>\n","      <td>231400</td>\n","      <td>mohammed v</td>\n","      <td>810</td>\n","      <td>rabat</td>\n","      <td>Rabat</td>\n","      <td>rabat-sale-kenitra</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>2009-01-02</td>\n","      <td>241000</td>\n","      <td>maamora</td>\n","      <td>330</td>\n","      <td>kenitra</td>\n","      <td>Kenitra</td>\n","      <td>rabat-sale-kenitra</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   atm_id        date  amount                     BRANCH_NAME  CITY_CODE  \\\n","0       1  2009-01-02   17200  zerktouni                             780   \n","1       2  2009-01-02  163300  zerktouni                             780   \n","2       3  2009-01-02  306900  centre d'affaire trabless             810   \n","3       4  2009-01-02  231400  mohammed v                            810   \n","4       5  2009-01-02  241000  maamora                               330   \n","\n","         city      city.1              region day_off_discription  \n","0  casablanca  Casablanca   casablanca-settat                 NaN  \n","1  casablanca  Casablanca   casablanca-settat                 NaN  \n","2       rabat       Rabat  rabat-sale-kenitra                 NaN  \n","3       rabat       Rabat  rabat-sale-kenitra                 NaN  \n","4     kenitra     Kenitra  rabat-sale-kenitra                 NaN  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T13:08:36.996321Z","iopub.status.busy":"2025-05-23T13:08:36.996002Z","iopub.status.idle":"2025-05-23T13:08:37.005296Z","shell.execute_reply":"2025-05-23T13:08:37.004140Z","shell.execute_reply.started":"2025-05-23T13:08:36.996292Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Index(['atm_id', 'date', 'amount', 'BRANCH_NAME', 'CITY_CODE', 'city',\n","       'city.1', 'region', 'day_off_discription'],\n","      dtype='object')"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df.columns"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T13:08:37.007618Z","iopub.status.busy":"2025-05-23T13:08:37.007327Z","iopub.status.idle":"2025-05-23T13:08:37.601382Z","shell.execute_reply":"2025-05-23T13:08:37.600456Z","shell.execute_reply.started":"2025-05-23T13:08:37.007596Z"},"trusted":true},"outputs":[],"source":["df=df.drop(columns=['city.1'])"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T13:08:37.602531Z","iopub.status.busy":"2025-05-23T13:08:37.602270Z","iopub.status.idle":"2025-05-23T13:08:37.610083Z","shell.execute_reply":"2025-05-23T13:08:37.609226Z","shell.execute_reply.started":"2025-05-23T13:08:37.602504Z"},"trusted":true},"outputs":[{"data":{"text/plain":["atm_id                  int64\n","date                   object\n","amount                 object\n","BRANCH_NAME            object\n","CITY_CODE               int64\n","city                   object\n","region                 object\n","day_off_discription    object\n","dtype: object"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.dtypes"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T14:20:09.396075Z","iopub.status.busy":"2025-05-23T14:20:09.395732Z","iopub.status.idle":"2025-05-23T14:20:09.670087Z","shell.execute_reply":"2025-05-23T14:20:09.669155Z","shell.execute_reply.started":"2025-05-23T14:20:09.396048Z"},"trusted":true},"outputs":[],"source":["df['date']=pd.to_datetime(df['date'])"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T13:08:38.614467Z","iopub.status.busy":"2025-05-23T13:08:38.614168Z","iopub.status.idle":"2025-05-23T13:08:40.866255Z","shell.execute_reply":"2025-05-23T13:08:40.865456Z","shell.execute_reply.started":"2025-05-23T13:08:38.614438Z"},"trusted":true},"outputs":[],"source":["# Extract the day of the year (1-365/366), useful for capturing seasonal trends\n","df['dayofyear'] = df['date'].dt.dayofyear\n","\n","# Apply sine transformation to encode cyclic nature of the year (seasonality)\n","df['sin_day'] = np.sin(2 * np.pi * df['dayofyear'] / 365.25)\n","\n","# Apply cosine transformation to complement sine and preserve angular distance\n","df['cos_day'] = np.cos(2 * np.pi * df['dayofyear'] / 365.25)\n","\n","# Extract the day of the week (0=Monday, 6=Sunday) to capture weekly patterns\n","df['day_of_week'] = df['date'].dt.dayofweek\n","\n","# Extract the day of the month (1-31), which may help if there are end/beginning-of-month effects\n","df['day_of_month'] = df['date'].dt.day\n","\n","# Extract the month of the year (1=Jan, 12=Dec), helpful for detecting seasonal cycles\n","df['month_of_year'] = df['date'].dt.month\n","\n","# Extract the ISO week number of the year (1-52/53), may help in capturing weekly seasonality\n","df['week_of_year'] = df['date'].dt.isocalendar().week\n","\n","# Binary flag indicating if it's the end of the month; can capture patterns in cash demand near month-end\n","df['is_end_of_month'] = (df['date'].dt.is_month_end).astype(int)\n","\n","# Binary flag indicating if it's the start of the month (first 3 days); useful if people withdraw early-month\n","df['is_start_of_month'] = (df['day_of_month'] <= 3).astype(int)\n","\n","# Number of days remaining until the end of the current month\n","df['days_until_month_end'] = df['date'].dt.days_in_month - df['day_of_month']\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T13:08:40.867338Z","iopub.status.busy":"2025-05-23T13:08:40.867127Z","iopub.status.idle":"2025-05-23T13:08:42.640707Z","shell.execute_reply":"2025-05-23T13:08:42.639803Z","shell.execute_reply.started":"2025-05-23T13:08:40.867322Z"},"trusted":true},"outputs":[],"source":["# Create a new categorical feature 'weekend_type' to classify days based on their proximity to the weekend\n","df['weekend_type'] = np.select(\n","    [\n","        df['day_of_week'] == 4,                    # If it's Friday (pre-weekend)\n","        df['day_of_week'].isin([5, 6])             # If it's Saturday or Sunday (weekend)\n","    ],\n","    [\n","        'pre_weekend',                             # Label Friday as 'pre_weekend'\n","        'weekend'                                  # Label Saturday and Sunday as 'weekend'\n","    ],\n","    default='workday'                              # Label all other days as 'workday'\n",")\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T13:08:42.641925Z","iopub.status.busy":"2025-05-23T13:08:42.641650Z","iopub.status.idle":"2025-05-23T13:08:43.237264Z","shell.execute_reply":"2025-05-23T13:08:43.236449Z","shell.execute_reply.started":"2025-05-23T13:08:42.641905Z"},"trusted":true},"outputs":[],"source":["# Fill missing values in 'day_off_discription' with 'normal day' to indicate no special event or holiday\n","df['day_off_discription'] = df['day_off_discription'].fillna('normal day')"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T13:08:43.239540Z","iopub.status.busy":"2025-05-23T13:08:43.239293Z","iopub.status.idle":"2025-05-23T13:08:45.174132Z","shell.execute_reply":"2025-05-23T13:08:45.173447Z","shell.execute_reply.started":"2025-05-23T13:08:43.239523Z"},"trusted":true},"outputs":[],"source":["# Replace specific non-holiday technical event descriptions with 'normal day'\n","# These events (e.g., migrations) are likely operational and not relevant to ATM cash demand\n","df['day_off_discription'] = df['day_off_discription'].replace({\n","    'migrations  du db2 et du cics': 'normal day',\n","    'migration z9 vers le z10': 'normal day',\n","    'migration des agences chaouia': 'normal day',\n","})"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T13:08:45.175361Z","iopub.status.busy":"2025-05-23T13:08:45.175060Z","iopub.status.idle":"2025-05-23T13:08:45.351280Z","shell.execute_reply":"2025-05-23T13:08:45.350537Z","shell.execute_reply.started":"2025-05-23T13:08:45.175333Z"},"trusted":true},"outputs":[],"source":["# Define a list of known holidays (religious, national, historical)\n","holidays = [\"manifeste de l'independance\", 'aid al adha', 'aid al fitr', 'aid al mawlid', 'premier moharram',\n","           'fete du trone', 'fete du travail', 'jour de l\\'an', \"fete de l'independance\", 'marche verte', \n","           'revolution du roi et du peuple', 'fete de la jeunesse', 'fete oued eddahab', 'nouvel an amazigh']\n","\n","# Create a binary flag indicating if the day is a holiday\n","df['is_holiday'] = df['day_off_discription'].isin(holidays).astype(int)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T13:08:45.352542Z","iopub.status.busy":"2025-05-23T13:08:45.352218Z","iopub.status.idle":"2025-05-23T13:41:13.989264Z","shell.execute_reply":"2025-05-23T13:41:13.988536Z","shell.execute_reply.started":"2025-05-23T13:08:45.352510Z"},"trusted":true},"outputs":[],"source":["# Function to compute the number of days since the last holiday for each date\n","def add_days_after_last_holiday(df):\n","    result_df = df.copy()  # Work on a copy to avoid modifying the original DataFrame\n","    \n","    result_df = result_df.sort_index()  # Ensure data is sorted by date for correct time difference calculations\n","\n","    # If no holidays exist in the data, create a column filled with NaNs and exit\n","    if sum(result_df['is_holiday'] == 1) == 0:\n","        print(\"No holidays found in the dataset\")\n","        result_df['days_after_last_holiday'] = np.nan\n","        return result_df\n","\n","    # Ensure the DataFrame index is in datetime format\n","    if not pd.api.types.is_datetime64_dtype(result_df.index):\n","        result_df.index = pd.to_datetime(result_df.index)\n","\n","    # Initialize the new column\n","    result_df['days_after_last_holiday'] = np.nan\n","    \n","    last_holiday = None  # Variable to keep track of the last holiday date\n","\n","    # Iterate through each date to compute days since the last holiday\n","    for date in result_df.index:\n","        is_holiday_val = result_df.loc[date, 'is_holiday']\n","\n","        # Handle the case where loc returns a Series (e.g., duplicate index)\n","        if isinstance(is_holiday_val, pd.Series):\n","            is_holiday_val = is_holiday_val.iloc[0]\n","        \n","        # Update last holiday date if current day is a holiday\n","        if is_holiday_val == 1:\n","            last_holiday = date\n","\n","        # Compute days since the last holiday if there was one\n","        if last_holiday is not None:\n","            delta = date - last_holiday\n","            result_df.loc[date, 'days_after_last_holiday'] = delta.days\n","    \n","    return result_df\n","\n","# Apply the function to the main DataFrame\n","df = add_days_after_last_holiday(df)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T13:41:13.991072Z","iopub.status.busy":"2025-05-23T13:41:13.990399Z","iopub.status.idle":"2025-05-23T13:41:14.774340Z","shell.execute_reply":"2025-05-23T13:41:14.773456Z","shell.execute_reply.started":"2025-05-23T13:41:13.991037Z"},"trusted":true},"outputs":[],"source":["#for memory restrictions , and we will work just with 3 years after\n","df = df[df['date'] >= '2021-01-01']"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T14:19:26.208520Z","iopub.status.busy":"2025-05-23T14:19:26.208213Z","iopub.status.idle":"2025-05-23T14:19:27.248676Z","shell.execute_reply":"2025-05-23T14:19:27.247944Z","shell.execute_reply.started":"2025-05-23T14:19:26.208498Z"},"trusted":true},"outputs":[],"source":["# Step 3: Infer an estimated urban zone type for each city\n","# List of 41 major Moroccan cities considered as \"urban\" (standardized to lowercase without accents)\n","urban_cities = [\n","    'casablanca', 'fes', 'tanger', 'marrakech', 'meknes', 'agadir', 'rabat', 'oujda', 'sale',\n","    'kenitra', 'tetouan', 'temara', 'safi', 'mohammedia', 'laayoune', 'el jadida', 'khouribga',\n","    'beni mellal', 'nador', 'guelmim', 'settat', 'khemisset', 'taza', 'larache', 'ait melloul',\n","    'al hoceima', 'bouskoura', 'inezgane', 'berkane', 'khenifra', 'taourirt', 'ben guerir',\n","    'dakhla', 'dcheira el jihadia', 'errachidia', 'sidi slimane', 'tiznit', 'taroudant',\n","    'guercif', 'essaouira', 'sidi kacem'\n","]\n","\n","# Create a new column 'zone_type' based on city membership in the urban list\n","# Assumes 'city' column is already in lowercase and normalized (no accents)\n","df['zone_type'] = df['city'].apply(\n","    lambda x: 'urbain' if x in urban_cities else 'rural'\n",")\n"]},{"cell_type":"code","execution_count":24,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2025-05-23T14:20:22.367643Z","iopub.status.busy":"2025-05-23T14:20:22.367283Z","iopub.status.idle":"2025-05-23T14:20:33.736324Z","shell.execute_reply":"2025-05-23T14:20:33.735550Z","shell.execute_reply.started":"2025-05-23T14:20:22.367618Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ferie_today             2656921\n","ferie_tomorrow          2653271\n","AidFitr_D-7               18049\n","AidFitr_D-6               17959\n","AidFitr_D-3               17954\n","AidFitr_D-2               17810\n","AidFitr_D-4               17789\n","AidFitr_D3                17773\n","AidFitr_D-5               17748\n","AidFitr_D2                17392\n","AidFitr_D-1               17153\n","AidFitr_D1                16816\n","AidFitr_day               16355\n","AidAdha_D-6               14599\n","AidAdha_D-13              14588\n","AidAdha_D8                14524\n","AidAdha_D7                14521\n","AidAdha_D-7               14502\n","AidAdha_D-14              14499\n","AidAdha_D4                14477\n","AidAdha_D-10              14431\n","AidAdha_D5                14430\n","AidAdha_D-12              14413\n","AidAdha_D-2               14407\n","AidAdha_D-3               14389\n","AidAdha_D-9               14370\n","AidAdha_D6                14349\n","AidAdha_D-11              14326\n","AidAdha_D9                14290\n","AidAdha_D-8               14283\n","AidAdha_D-5               14246\n","AidAdha_D3                14245\n","AidAdha_D2                14200\n","AidAdha_D10               14192\n","AidAdha_D-4               14098\n","AidAdha_D-15              14062\n","AidAdha_D-1               13651\n","AidAdha_D1                13645\n","AidAdha_day               13006\n","Revolution20aout_D-1       7281\n","Revolution20aout_D-2       7176\n","FeteTravail_D-1            7041\n","Revolution20aout_day       7024\n","Revolution20aout_D1        6769\n","FeteTravail_day            6534\n","dtype: int64\n"]}],"source":["# Generic function to create temporal indicators (binary flags) around a specific event\n","def create_event_window(df, event_name, prefix, days_before=0, days_after=0):\n","    event_dates = df[df['day_off_discription'] == event_name]['date'].unique()\n","    for i in range(-days_before, days_after + 1):\n","        col = f\"{prefix}_D{i}\" if i != 0 else f\"{prefix}_day\"\n","        df[col] = df['date'].isin([d + pd.Timedelta(days=i) for d in event_dates]).astype(int)\n","    return df\n","\n","# 1. Aid al-Adha: significant impact from 15 days before to 10 days after; peak at D-1, very low on D0\n","df = create_event_window(df, 'aid al adha', 'AidAdha', days_before=15, days_after=10)\n","\n","# 2. Aid al-Fitr: impact from 7 days before to 3 days after\n","df = create_event_window(df, 'aid al fitr', 'AidFitr', days_before=7, days_after=3)\n","\n","# 3. Mawlid (Prophet's birthday): impact from 2 days before to 2 days after\n","df = create_event_window(df, 'aid al mawlid', 'Mawlid', days_before=2, days_after=2)\n","\n","# 4. 1st Moharram (Islamic New Year): impact from 1 day before to 1 day after\n","df = create_event_window(df, 'premier moharram', 'Hijri', days_before=1, days_after=1)\n","\n","# 5. Labour Day (May 1st): impact from 1 day before to the same day\n","df = create_event_window(df, 'fete du travail', 'FeteTravail', days_before=1, days_after=0)\n","\n","# 6. Throne Day: impact from 1 day before to 1 day after\n","df = create_event_window(df, 'fete du trone', 'FeteTrone', days_before=1, days_after=1)\n","\n","# 7. Revolution of the King and the People + Youth Day (Aug 20–21): impact from 2 days before to 1 day after\n","df = create_event_window(df, 'revolution du roi et du peuple', 'Revolution20aout', days_before=2, days_after=1)\n","df = create_event_window(df, 'fete de la jeunesse', 'Jeunesse21aout', days_before=1, days_after=1)\n","\n","# 8. Green March (Nov 6): impact from 1 day before to 1 day after\n","df = create_event_window(df, 'marche verte', 'MarcheVerte', days_before=1, days_after=1)\n","\n","# 9. Independence Day (Nov 18): impact from 1 day before to 1 day after\n","df = create_event_window(df, 'fete de l\\'independance', 'FeteIndependance', days_before=1, days_after=1)\n","\n","# 10. Manifesto of Independence (Jan 11): impact from 1 day before to the same day\n","df = create_event_window(df, 'manifeste de l\\'independance', 'ManifesteIndep', days_before=1, days_after=0)\n","\n","# 11. New Year's Day (Jan 1): impact from 1 day before to the same day\n","df = create_event_window(df, 'jour de l\\'an', 'JourAn', days_before=1, days_after=0)\n","\n","# 12. Oued Eddahab Day: low effect, only mark the exact day\n","df['FeteOuedEddahab_day'] = (df['day_off_discription'] == 'fete oued eddahab').astype(int)\n","\n","# 13. Amazigh New Year: minor effect, only mark the exact day\n","df['NouvelAnAmazigh_day'] = (df['day_off_discription'] == 'nouvel an amazigh').astype(int)\n","\n","# 14. Create general features for whether today or tomorrow is a holiday\n","df['ferie_today'] = (df['day_off_discription'] != 'normal Day').astype(int)\n","df['ferie_tomorrow'] = df['date'].isin(df[df['day_off_discription'] != 'normal Day']['date'] - pd.Timedelta(days=1)).astype(int)\n","\n","# Quick check: summarize and print the counts of certain event-related columns\n","event_cols = [col for col in df.columns if any(key in col for key in ['AidAdha', 'AidFitr', 'ferie', 'Revolution', 'FeteTravail'])]\n","print(df[event_cols].sum().sort_values(ascending=False))"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T14:22:56.085460Z","iopub.status.busy":"2025-05-23T14:22:56.084407Z","iopub.status.idle":"2025-05-23T14:22:57.810211Z","shell.execute_reply":"2025-05-23T14:22:57.809151Z","shell.execute_reply.started":"2025-05-23T14:22:56.085429Z"},"trusted":true},"outputs":[],"source":["# Replace comma with dot and convert to float\n","df['amount'] = df['amount'].astype(str).str.replace(',', '.').astype(float)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T14:23:04.583153Z","iopub.status.busy":"2025-05-23T14:23:04.582837Z","iopub.status.idle":"2025-05-23T14:27:58.789541Z","shell.execute_reply":"2025-05-23T14:27:58.788590Z","shell.execute_reply.started":"2025-05-23T14:23:04.583131Z"},"trusted":true},"outputs":[],"source":["# Sort the dataframe by atm_id and date to ensure proper time series order\n","df = df.sort_values(['atm_id', 'date'])\n","\n","# Calculate rolling (moving) averages and standard deviation over 7 and 30 days per ATM\n","df['mm7'] = df.groupby('atm_id')['amount'].transform(\n","    lambda x: x.rolling(7, min_periods=1).mean()\n",")  # 7-day moving average\n","\n","df['mm30'] = df.groupby('atm_id')['amount'].transform(\n","    lambda x: x.rolling(30, min_periods=1).mean()\n",")  # 30-day moving average\n","\n","df['std7'] = df.groupby('atm_id')['amount'].transform(\n","    lambda x: x.rolling(7, min_periods=1).std()\n",")  # 7-day rolling standard deviation\n","\n","# Coefficient of variation over 7 days: std / mean (adding small epsilon to avoid division by zero)\n","df['cv7'] = df['std7'] / (df['mm7'] + 1e-6)\n","\n","# Calculate 14-day trend: difference between average of last 7 days and first 7 days in a rolling window\n","def trend_14d(x):\n","    return x.rolling(14, min_periods=1).apply(\n","        lambda y: y[-7:].mean() - y[:7].mean() if len(y) == 14 else 0\n","    )\n","\n","df['trend7'] = df.groupby('atm_id')['amount'].transform(trend_14d)\n","\n","# Create lagged features for previous days' amounts (lags 1 to 7, 14, and 30 days)\n","df['lag_1'] = df.groupby('atm_id')['amount'].shift(1)\n","df['lag_2'] = df.groupby('atm_id')['amount'].shift(2)\n","df['lag_3'] = df.groupby('atm_id')['amount'].shift(3)\n","df['lag_4'] = df.groupby('atm_id')['amount'].shift(4)\n","df['lag_5'] = df.groupby('atm_id')['amount'].shift(5)\n","df['lag_6'] = df.groupby('atm_id')['amount'].shift(6)\n","df['lag_7'] = df.groupby('atm_id')['amount'].shift(7)\n","df['lag_14'] = df.groupby('atm_id')['amount'].shift(14)\n","df['lag_30'] = df.groupby('atm_id')['amount'].shift(30)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T14:40:05.102283Z","iopub.status.busy":"2025-05-23T14:40:05.101838Z","iopub.status.idle":"2025-05-23T14:40:08.550731Z","shell.execute_reply":"2025-05-23T14:40:08.549780Z","shell.execute_reply.started":"2025-05-23T14:40:05.102251Z"},"trusted":true},"outputs":[],"source":["# Calculate the average withdrawal amount on weekends (Saturday=5, Sunday=6) per ATM\n","weekend_avg = df[df['day_of_week'].isin([5, 6])].groupby('atm_id')['amount'].mean()\n","\n","# Calculate the average withdrawal amount on weekdays (non-weekend days) per ATM\n","weekday_avg = df[~df['day_of_week'].isin([5, 6])].groupby('atm_id')['amount'].mean()\n","\n","# Compute the ratio of weekend average to weekday average, adding a small epsilon to avoid division by zero\n","weekend_weekday_ratio = (weekend_avg / (weekday_avg + 1e-6)).reset_index()\n","\n","# Rename columns for clarity\n","weekend_weekday_ratio.columns = ['atm_id', 'weekend_weekday_ratio']\n","\n","# Merge this ratio back into the original dataframe, matching on atm_id\n","df = df.merge(weekend_weekday_ratio, on='atm_id', how='left')"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T14:40:11.334006Z","iopub.status.busy":"2025-05-23T14:40:11.333342Z","iopub.status.idle":"2025-05-23T14:40:12.631992Z","shell.execute_reply":"2025-05-23T14:40:12.630925Z","shell.execute_reply.started":"2025-05-23T14:40:11.333977Z"},"trusted":true},"outputs":[],"source":["# Calculate the rolling minimum withdrawal amount over the past 30 days for each ATM\n","df['min30'] = df.groupby('atm_id')['amount'].transform(\n","    lambda x: x.rolling(30, min_periods=1).min()\n",")\n","\n","# Calculate the rolling maximum withdrawal amount over the past 30 days for each ATM\n","df['max30'] = df.groupby('atm_id')['amount'].transform(\n","    lambda x: x.rolling(30, min_periods=1).max()\n",")\n"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T15:02:06.103305Z","iopub.status.busy":"2025-05-23T15:02:06.102845Z","iopub.status.idle":"2025-05-23T15:02:06.121434Z","shell.execute_reply":"2025-05-23T15:02:06.120431Z","shell.execute_reply.started":"2025-05-23T15:02:06.103275Z"},"trusted":true},"outputs":[],"source":["df['date']=df['date'].astype(int)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T15:02:09.306166Z","iopub.status.busy":"2025-05-23T15:02:09.305835Z","iopub.status.idle":"2025-05-23T15:06:19.832140Z","shell.execute_reply":"2025-05-23T15:06:19.831240Z","shell.execute_reply.started":"2025-05-23T15:02:09.306139Z"},"trusted":true},"outputs":[],"source":["# Number of low withdrawal days (< 1000 MAD) over the past 30 days for each ATM\n","df['nb_jours_faibles30'] = df.groupby('atm_id')['amount'].transform(\n","    lambda x: x.rolling(30, min_periods=1).apply(lambda y: (y < 1000).sum())\n",")\n","\n","# Daily total amount withdrawn per city\n","df['total_city_day'] = df.groupby(['city', 'date'])['amount'].transform('sum')\n","\n","# Ratio of ATM withdrawal amount relative to the city total for the day\n","df['atm_ratio_city'] = df['amount'] / (df['total_city_day'] + 1e-6)\n","\n","# Daily total amount withdrawn per region (note: grouping by 'region' and 'amount' might be incorrect; see below)\n","df['total_region_day'] = df.groupby(['region', 'amount'])['amount'].transform('sum')\n","\n","# Ratio of ATM withdrawal amount relative to the region total for the day\n","df['atm_ratio_region'] = df['amount'] / (df['total_region_day'] + 1e-6)\n","\n","# Daily total amount withdrawn per branch (note: grouping by 'BRANCH_NAME' and 'date' but summing 'date' column seems off; see below)\n","df['total_branch_day'] = df.groupby(['BRANCH_NAME', 'date'])['date'].transform('sum')\n","\n","# Ratio of ATM withdrawal amount relative to the branch total for the day\n","df['atm_ratio_branch'] = df['amount'] / (df['total_branch_day'] + 1e-6)\n","\n","# Daily total amount withdrawn nationwide\n","df['total_global_day'] = df.groupby('date')['amount'].transform('sum')\n","\n","# Ratio of ATM withdrawal amount relative to the national total for the day\n","df['atm_relative_to_global'] = df['amount'] / (df['total_global_day'] + 1e-6)\n","\n","# Rank of each ATM within its city on a given day, based on withdrawal amount (descending order)\n","df['atm_rank_city'] = df.groupby(['city', 'date'])['amount'].rank(method='min', ascending=False)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T15:07:26.610410Z","iopub.status.busy":"2025-05-23T15:07:26.610058Z","iopub.status.idle":"2025-05-23T15:07:27.714280Z","shell.execute_reply":"2025-05-23T15:07:27.713414Z","shell.execute_reply.started":"2025-05-23T15:07:26.610387Z"},"trusted":true},"outputs":[],"source":["df['date']=pd.to_datetime(df['date'])"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T15:12:29.648028Z","iopub.status.busy":"2025-05-23T15:12:29.647660Z","iopub.status.idle":"2025-05-23T15:16:30.510175Z","shell.execute_reply":"2025-05-23T15:16:30.509391Z","shell.execute_reply.started":"2025-05-23T15:12:29.648005Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_97/2646777334.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  df['atm_is_top10_city'] = df.groupby(['city', 'date']).apply(is_top_10).reset_index(drop=True)\n"]}],"source":["# Function to identify if the ATM's amount is in the top 10% within its city on a given day\n","def is_top_10(group):\n","    threshold = np.percentile(group['amount'], 90)  # 90th percentile threshold\n","    return (group['amount'] >= threshold).astype(int)  # Mark as 1 if above or equal, else 0\n","\n","# Apply the function to each group defined by city and date, then assign results to a new column\n","df['atm_is_top10_city'] = df.groupby(['city', 'date']).apply(is_top_10).reset_index(drop=True)\n","\n","# Compute 7-day rolling mean of 'mm7' feature for each city\n","df['mm7_city'] = df.groupby('city')['mm7'].transform(lambda x: x.rolling(7, min_periods=1).mean())\n","\n","# Compute the ratio of ATM’s 7-day moving average to the city’s 7-day moving average\n","df['atm_ratio_city_mm7'] = df['mm7'] / (df['mm7_city'] + 1e-6)\n"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T15:17:35.258545Z","iopub.status.busy":"2025-05-23T15:17:35.258179Z","iopub.status.idle":"2025-05-23T15:20:14.971819Z","shell.execute_reply":"2025-05-23T15:20:14.970714Z","shell.execute_reply.started":"2025-05-23T15:17:35.258520Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_97/1905830804.py:47: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  df= df.groupby('atm_id').apply(compute_gaps)\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","# Define thresholds based on the data distribution (you can tune these)\n","HIGH_DEPOSIT_THRESHOLD = df['amount'].quantile(0.90)  # Threshold for top 10% deposits\n","LOW_DEPOSIT_THRESHOLD = df['amount'].quantile(0.10)   # Threshold for bottom 10% deposits\n","SPIKE_THRESHOLD = df['amount'].mean() * 1.5           # Threshold for spikes (1.5 times the mean amount)\n","\n","# Initialize new columns for gap features with default zero values\n","df['rolling_max_gap'] = 0          # Days since last high deposit\n","df['rolling_min_gap'] = 0          # Days since last low deposit\n","df['days_since_last_spike'] = 0    # Days since last spike event\n","\n","# Function to calculate gap features for each ATM's time series\n","def compute_gaps(group):\n","    max_gap = []   # To store days since last high deposit\n","    min_gap = []   # To store days since last low deposit\n","    spike_gap = [] # To store days since last spike\n","\n","    last_high = None   # Last date when deposit was high\n","    last_low = None    # Last date when deposit was low\n","    last_spike = None  # Last date when deposit was a spike\n","\n","    # Iterate over each row in the ATM group (sorted by date)\n","    for _, row in group.iterrows():\n","        current_date = row['date']\n","        amount = row['amount']\n","\n","        # Update last_high if current amount is high\n","        if amount >= HIGH_DEPOSIT_THRESHOLD:\n","            last_high = current_date\n","        # Calculate days since last high deposit or NaN if none before\n","        max_gap.append((current_date - last_high).days if last_high else np.nan)\n","\n","        # Update last_low if current amount is low\n","        if amount <= LOW_DEPOSIT_THRESHOLD:\n","            last_low = current_date\n","        # Calculate days since last low deposit or NaN if none before\n","        min_gap.append((current_date - last_low).days if last_low else np.nan)\n","\n","        # Update last_spike if current amount is a spike\n","        if amount >= SPIKE_THRESHOLD:\n","            last_spike = current_date\n","        # Calculate days since last spike or NaN if none before\n","        spike_gap.append((current_date - last_spike).days if last_spike else np.nan)\n","\n","    # Assign the computed gap lists back to the group's new columns\n","    group['rolling_max_gap'] = max_gap\n","    group['rolling_min_gap'] = min_gap\n","    group['days_since_last_spike'] = spike_gap\n","\n","    return group\n","\n","# Apply the gap computation function to each ATM group in the dataframe\n","df = df.groupby('atm_id').apply(compute_gaps)"]},{"cell_type":"code","execution_count":41,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2025-05-23T15:24:35.966423Z","iopub.status.busy":"2025-05-23T15:24:35.966036Z","iopub.status.idle":"2025-05-23T15:24:36.014845Z","shell.execute_reply":"2025-05-23T15:24:36.013888Z","shell.execute_reply.started":"2025-05-23T15:24:35.966395Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_97/3283717924.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df['rolling_max_gap'].fillna(0, inplace=True)\n","/tmp/ipykernel_97/3283717924.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df['rolling_min_gap'].fillna(0, inplace=True)\n","/tmp/ipykernel_97/3283717924.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df['days_since_last_spike'].fillna(0, inplace=True)\n"]}],"source":["# Replace NaN values in the gap columns with 0\n","df['rolling_max_gap'] = df['rolling_max_gap'].fillna(0)\n","df['rolling_min_gap'] = df['rolling_min_gap'].fillna(0)\n","df['days_since_last_spike'] = df['days_since_last_spike'].fillna(0)\n"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T15:34:26.926582Z","iopub.status.busy":"2025-05-23T15:34:26.926246Z","iopub.status.idle":"2025-05-23T15:34:31.303459Z","shell.execute_reply":"2025-05-23T15:34:31.302435Z","shell.execute_reply.started":"2025-05-23T15:34:26.926560Z"},"trusted":true},"outputs":[],"source":["df= df.reset_index(level='atm_id', drop=True)\n"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T15:34:54.770257Z","iopub.status.busy":"2025-05-23T15:34:54.769819Z","iopub.status.idle":"2025-05-23T15:34:54.911800Z","shell.execute_reply":"2025-05-23T15:34:54.910865Z","shell.execute_reply.started":"2025-05-23T15:34:54.770226Z"},"trusted":true},"outputs":[],"source":["# Calculate average amount per ATM and day of week\n","df['avg_by_dow'] = df.groupby(['atm_id', 'day_of_week'])['amount'].transform('mean')"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T15:34:58.867930Z","iopub.status.busy":"2025-05-23T15:34:58.867423Z","iopub.status.idle":"2025-05-23T15:35:00.320634Z","shell.execute_reply":"2025-05-23T15:35:00.319582Z","shell.execute_reply.started":"2025-05-23T15:34:58.867892Z"},"trusted":true},"outputs":[],"source":["# Calculate 7-day lag correlation of amount per ATM\n","df['lag_corr_7'] = df.groupby('atm_id')['amount'].transform(\n","    lambda x: x.shift(7).corr(x)\n",")"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T15:35:04.698770Z","iopub.status.busy":"2025-05-23T15:35:04.698340Z","iopub.status.idle":"2025-05-23T15:35:04.835102Z","shell.execute_reply":"2025-05-23T15:35:04.833892Z","shell.execute_reply.started":"2025-05-23T15:35:04.698734Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Colonnes de type object : ['BRANCH_NAME', 'city', 'region', 'day_off_discription', 'weekend_type', 'zone_type']\n"]}],"source":["# Obtenir la liste des colonnes de type object (catégorielles ou string)\n","object_features = df.select_dtypes(include='object').columns.tolist()\n","\n","# Affichage\n","print(\"Colonnes de type object :\", object_features)"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T15:38:54.752850Z","iopub.status.busy":"2025-05-23T15:38:54.752470Z","iopub.status.idle":"2025-05-23T15:38:59.239780Z","shell.execute_reply":"2025-05-23T15:38:59.238868Z","shell.execute_reply.started":"2025-05-23T15:38:54.752824Z"},"trusted":true},"outputs":[],"source":["# Drop columns 'BRANCH_NAME' and 'city' as their information is already captured elsewhere\n","df = df.drop(columns=['BRANCH_NAME', 'city'])\n","\n","# Use label encoding for categorical columns where ordinal encoding is acceptable\n","from sklearn.preprocessing import LabelEncoder\n","\n","for col in ['region', 'zone_type', 'day_off_discription', 'weekend_type']:\n","    df[col] = LabelEncoder().fit_transform(df[col])"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T15:39:08.190683Z","iopub.status.busy":"2025-05-23T15:39:08.190177Z","iopub.status.idle":"2025-05-23T15:39:08.214294Z","shell.execute_reply":"2025-05-23T15:39:08.213324Z","shell.execute_reply.started":"2025-05-23T15:39:08.190652Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>atm_id</th>\n","      <th>date</th>\n","      <th>amount</th>\n","      <th>CITY_CODE</th>\n","      <th>region</th>\n","      <th>day_off_discription</th>\n","      <th>dayofyear</th>\n","      <th>sin_day</th>\n","      <th>cos_day</th>\n","      <th>day_of_week</th>\n","      <th>...</th>\n","      <th>atm_relative_to_global</th>\n","      <th>atm_rank_city</th>\n","      <th>atm_is_top10_city</th>\n","      <th>mm7_city</th>\n","      <th>atm_ratio_city_mm7</th>\n","      <th>rolling_max_gap</th>\n","      <th>rolling_min_gap</th>\n","      <th>days_since_last_spike</th>\n","      <th>avg_by_dow</th>\n","      <th>lag_corr_7</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2021-01-01</td>\n","      <td>21700.0</td>\n","      <td>780</td>\n","      <td>12</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>0.017202</td>\n","      <td>0.999852</td>\n","      <td>4</td>\n","      <td>...</td>\n","      <td>0.000067</td>\n","      <td>225.0</td>\n","      <td>0</td>\n","      <td>21700.000000</td>\n","      <td>1.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>52822.435071</td>\n","      <td>0.223148</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2021-01-02</td>\n","      <td>25000.0</td>\n","      <td>780</td>\n","      <td>12</td>\n","      <td>11</td>\n","      <td>2</td>\n","      <td>0.034398</td>\n","      <td>0.999408</td>\n","      <td>5</td>\n","      <td>...</td>\n","      <td>0.000079</td>\n","      <td>217.0</td>\n","      <td>1</td>\n","      <td>22525.000000</td>\n","      <td>1.036626</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>27622.681014</td>\n","      <td>0.223148</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>2021-01-03</td>\n","      <td>13100.0</td>\n","      <td>780</td>\n","      <td>12</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>0.051584</td>\n","      <td>0.998669</td>\n","      <td>6</td>\n","      <td>...</td>\n","      <td>0.000060</td>\n","      <td>206.0</td>\n","      <td>0</td>\n","      <td>21661.111111</td>\n","      <td>0.920236</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>14087.452791</td>\n","      <td>0.223148</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>2021-01-04</td>\n","      <td>59500.0</td>\n","      <td>780</td>\n","      <td>12</td>\n","      <td>11</td>\n","      <td>4</td>\n","      <td>0.068755</td>\n","      <td>0.997634</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.000137</td>\n","      <td>231.0</td>\n","      <td>1</td>\n","      <td>23702.083333</td>\n","      <td>1.258328</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>52893.875167</td>\n","      <td>0.223148</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>2021-01-05</td>\n","      <td>47200.0</td>\n","      <td>780</td>\n","      <td>12</td>\n","      <td>11</td>\n","      <td>5</td>\n","      <td>0.085906</td>\n","      <td>0.996303</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0.000130</td>\n","      <td>232.0</td>\n","      <td>0</td>\n","      <td>25621.666667</td>\n","      <td>1.299681</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>52377.701053</td>\n","      <td>0.223148</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 126 columns</p>\n","</div>"],"text/plain":["   atm_id       date   amount  CITY_CODE  region  day_off_discription  \\\n","0       1 2021-01-01  21700.0        780      12                    8   \n","1       1 2021-01-02  25000.0        780      12                   11   \n","2       1 2021-01-03  13100.0        780      12                   11   \n","3       1 2021-01-04  59500.0        780      12                   11   \n","4       1 2021-01-05  47200.0        780      12                   11   \n","\n","   dayofyear   sin_day   cos_day  day_of_week  ...  atm_relative_to_global  \\\n","0          1  0.017202  0.999852            4  ...                0.000067   \n","1          2  0.034398  0.999408            5  ...                0.000079   \n","2          3  0.051584  0.998669            6  ...                0.000060   \n","3          4  0.068755  0.997634            0  ...                0.000137   \n","4          5  0.085906  0.996303            1  ...                0.000130   \n","\n","   atm_rank_city  atm_is_top10_city      mm7_city  atm_ratio_city_mm7  \\\n","0          225.0                  0  21700.000000            1.000000   \n","1          217.0                  1  22525.000000            1.036626   \n","2          206.0                  0  21661.111111            0.920236   \n","3          231.0                  1  23702.083333            1.258328   \n","4          232.0                  0  25621.666667            1.299681   \n","\n","   rolling_max_gap  rolling_min_gap  days_since_last_spike    avg_by_dow  \\\n","0              0.0              0.0                    0.0  52822.435071   \n","1              0.0              0.0                    0.0  27622.681014   \n","2              0.0              0.0                    0.0  14087.452791   \n","3              0.0              1.0                    0.0  52893.875167   \n","4              0.0              0.0                    0.0  52377.701053   \n","\n","   lag_corr_7  \n","0    0.223148  \n","1    0.223148  \n","2    0.223148  \n","3    0.223148  \n","4    0.223148  \n","\n","[5 rows x 126 columns]"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T15:42:13.526095Z","iopub.status.busy":"2025-05-23T15:42:13.525279Z","iopub.status.idle":"2025-05-23T15:42:16.325294Z","shell.execute_reply":"2025-05-23T15:42:16.324340Z","shell.execute_reply.started":"2025-05-23T15:42:13.526067Z"},"trusted":true},"outputs":[],"source":["df=df.reset_index()"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T15:42:22.074895Z","iopub.status.busy":"2025-05-23T15:42:22.074580Z","iopub.status.idle":"2025-05-23T15:42:22.791216Z","shell.execute_reply":"2025-05-23T15:42:22.790272Z","shell.execute_reply.started":"2025-05-23T15:42:22.074871Z"},"trusted":true},"outputs":[],"source":["df = df[df['date'] >= '2022-01-01']"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T15:42:29.602428Z","iopub.status.busy":"2025-05-23T15:42:29.601530Z","iopub.status.idle":"2025-05-23T15:42:30.687890Z","shell.execute_reply":"2025-05-23T15:42:30.686912Z","shell.execute_reply.started":"2025-05-23T15:42:29.602398Z"},"trusted":true},"outputs":[],"source":["df=df.drop_duplicates(subset=['atm_id','date'])"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T15:42:50.824422Z","iopub.status.busy":"2025-05-23T15:42:50.823420Z","iopub.status.idle":"2025-05-23T15:42:51.548172Z","shell.execute_reply":"2025-05-23T15:42:51.547524Z","shell.execute_reply.started":"2025-05-23T15:42:50.824391Z"},"trusted":true},"outputs":[],"source":["df=df.set_index('date')"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2025-05-23T15:43:28.648563Z","iopub.status.busy":"2025-05-23T15:43:28.648217Z","iopub.status.idle":"2025-05-23T15:45:51.436882Z","shell.execute_reply":"2025-05-23T15:45:51.436039Z","shell.execute_reply.started":"2025-05-23T15:43:28.648535Z"},"trusted":true},"outputs":[],"source":["df.to_csv('/kaggle/working/final_atm_data.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":7150375,"sourceId":11922729,"sourceType":"datasetVersion"}],"dockerImageVersionId":31040,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"}},"nbformat":4,"nbformat_minor":4}
